**SISR** (Single Image Super Resolution) $-$ задача увеличения разрешения *одного* изображения. Из входного изображения с низким разрешением (Low Resolution, LR) необходимо реконструировать изображение с 
высоким разрешением (Super Resolution, SR), которое будет максимально похоже на изначальное фото (High Resolution, HR). Для многих подходов, использующих нейронные сети, применяются *попиксельные (pixel-wise)* функции потерь (например, *MSE* или *MAE*). 
Минимизация такой ошибки приводит к тому, что модель находит средние вероятностные решения для каждого пикселя, поэтому они получаются слишком гладкими и, следовательно, имеют низкое качество восприятия.

**SRGAN**

[Оригинальная статья](https://arxiv.org/pdf/1609.04802.pdf)

SRGAN (Super Resolution GAN) $-$ подход к решению задачи SISR, основанный на GAN-ах (генеративно-состязательных сетях). Основу генеративной сети составляют `B` residual блоков с одинаковой структурой. 
В каждом блоке находятся два свёрточных слоя с ядрами 3x3 и 64 каналами, за которыми расположены [batch-norm](https://habr.com/ru/post/309302/) слои. В качестве функции активации используется [PReLU (Parametric Rectified Linear Unit)](https://congyuzhou.medium.com/prelu-e0bc339d9c01). Входное изображение увеличивается попиксельно с помощью двух свёрточных слоев с операцией [PixelShuffle](https://paperswithcode.com/method/pixelshuffle) и функцией активации PReLU.

В качестве дискриминатора используется типичная для классификатора изображений архитектура с fully-connected слоями в конце.

Архитектуры генератора и дискриминатора в картинке:

![SRGAN structure](srgan_architecture.png)

Обучение модели разделено на два этапа: сначала на обычной MAE обучен генератор и получена сеть, которую называют SRResNet. Затем обучен SRGAN, проинициализованный весами SRResNet и использующий комбинированную 
функцию потерь, включающую взвешенные Perceptual Loss (MSE в пространстве признаков предобученной сети VGG), Adversarial loss с добалвением небольшого шума и MAE. Такое разделение необходимо, 
чтобы генератор не выдавал шум на начальных стадиях обучения и дискриминатор не начинал сразу выигрывать. Это позволяет избежать попадания в нежелательный локальный минимум при обучении SRGAN.


**Вывод**

На самом деле, в результатах данной работы лишь можно проследить перспективу предлагаемого подхода, поскольку полноценная реализация подразумевает гораздо более долгое обучение как сети SRResNet, так и SRGAN. 
С результатами можно ознакомиться по [ссылке](https://wandb.ai/vovan-frolov2011/Single%20Image%20Super%20Resolution/workspace?nw=nwuservovanfrolov2011). Здесь раны с названием `Generator_pretrain` соответствуют 
обучению сети SRResNet, а `SRGAN_training` $-$ обучению SRGAN. Качество SRGAN оставляет желать лучшего, но если проследить результаты результаты ранов в хронологической последовательности, то видится, что его можно обучать подольше и возможно будут получены хорошие результаты, однако возможно также, что требуется и более долгое предобучение сети SRResNet.
Качество SRResNet на первый взгляд достаточно хорошее, но если присмотреться, то оно результирующие изображения отличаются от исходных, однако, судя по метрикам, качество неплохое. Да, стоит учитывать, что представленные модели
обучались далеко не столько, сколько рекомендовано в оригинальной статье ($10^6$ итераций для SRResNet и $10^5$ итераций для SRGAN), поскольку время и ресурсы были ограничены.

К сожалению, даже правильно обученная модель будет недостаточно хорошо работать на многих изображениях из-за различных шумов. Например, она будет давать плохой результат на фотографиях с расширениями jpg/jpeg. 
Формат jpeg использует алгоритмы сжатия изображений, поэтому, чтобы модель хорошо работала и на них, нужно ее обучить убирать артефакты сжатия. 
